{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 定义专家\n",
    "class BasicExpert(nn.Module):\n",
    "    def __init__(self, features_in, features_out):\n",
    "        super().__init__()\n",
    "        self.f = nn.Linear(features_in, features_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BasicMoE(nn.Module):\n",
    "    def __init__(self, features_in, features_out, num_experts):\n",
    "        \"\"\"MoE实现\"\"\"\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(features_in, num_experts)\n",
    "\n",
    "        self.experts = nn.ModuleList(\n",
    "            BasicExpert(\n",
    "                features_in,features_out\n",
    "            ) for _ in range(num_experts)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        expert_weights = self.gate(x)\n",
    "        expert_out_list = [\n",
    "            expert(x) for expert in self.experts\n",
    "        ]  # 每一个expert输出一个(batch, feature_out)\n",
    "\n",
    "        expert_outputs = [\n",
    "            expert_out.unsqueeze(1)\n",
    "            for expert_out in expert_out_list\n",
    "        ]\n",
    "\n",
    "        # expert output(b, 1, feature_out)\n",
    "        expert_output = torch.concat(\n",
    "                expert_outputs,\n",
    "                dim=1,\n",
    "        )\n",
    "\n",
    "        expert_weights = F.softmax(expert_weights, dim=1)\n",
    "\n",
    "        expert_weights = expert_weights.unsqueeze(1)\n",
    "        output = expert_weights @ expert_output\n",
    "        return output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.6325e-02,  2.0662e-01,  2.2977e-02, -8.4462e-02, -2.5342e-01,\n",
      "          2.3081e-01, -1.0448e-02, -1.5514e-01, -2.2544e-01, -1.9022e-01,\n",
      "         -3.0879e-03, -2.5351e-01,  3.5677e-01,  8.6907e-02,  8.7096e-02,\n",
      "          3.6754e-02,  2.0798e-01, -6.3753e-03,  3.9717e-01,  2.1782e-02,\n",
      "          4.2338e-02,  1.4011e-01, -1.6863e-01, -1.6302e-01,  2.1730e-01,\n",
      "         -3.5477e-02,  1.3021e-01, -4.5069e-01,  4.7473e-03, -1.7201e-01,\n",
      "          7.1447e-02, -4.2137e-02, -4.3878e-03,  1.1961e-01, -9.9498e-02,\n",
      "          1.0333e-01,  2.2167e-01, -3.2443e-02, -1.8130e-02,  1.9047e-01,\n",
      "         -2.5822e-01, -1.0243e-01,  1.8449e-01, -3.7699e-03,  8.2029e-02,\n",
      "          2.4209e-01,  2.1167e-01,  8.6227e-02,  1.5288e-01,  1.3335e-01,\n",
      "          3.4756e-01, -2.6244e-01,  5.3349e-02,  7.4197e-02, -9.7490e-02,\n",
      "         -1.7634e-01, -5.3507e-02,  7.4848e-02,  9.3969e-03,  3.8816e-01,\n",
      "          1.2948e-01,  2.4515e-01,  3.2426e-02, -7.8446e-02,  5.7149e-02,\n",
      "          1.7013e-02, -1.7828e-01,  2.0959e-01, -1.9113e-01, -5.1347e-02,\n",
      "          3.1692e-01, -9.0371e-02, -5.3361e-02, -3.1732e-02, -1.3670e-01,\n",
      "          8.8089e-02,  2.1342e-02,  2.6179e-01,  1.5429e-01,  4.2555e-03,\n",
      "         -1.6686e-01,  9.1221e-02, -1.4196e-01,  2.4926e-01,  6.9373e-02,\n",
      "         -1.2221e-01,  1.0073e-01,  2.1238e-02,  1.3993e-01,  3.1037e-02,\n",
      "          3.2034e-02, -5.8529e-03, -1.8302e-01, -1.8347e-01,  4.3295e-02,\n",
      "         -1.2267e-01,  5.7180e-03,  2.0289e-02,  2.0573e-01,  1.0202e-01,\n",
      "         -2.8818e-03, -3.5232e-02, -1.0909e-01,  6.3270e-02, -1.7575e-01,\n",
      "          6.2429e-02,  3.2110e-01,  6.3451e-02, -1.3571e-01, -1.6834e-01,\n",
      "         -2.3545e-01, -1.1945e-01, -2.7027e-01,  1.0341e-01, -7.0970e-02,\n",
      "         -1.0758e-01,  2.1272e-02, -1.7157e-02, -2.4230e-03,  2.0732e-01,\n",
      "         -7.4149e-02, -4.7193e-02,  1.3331e-01,  1.7285e-02,  1.1089e-02,\n",
      "         -1.4003e-01,  3.6240e-01,  1.1114e-02],\n",
      "        [ 3.5996e-02,  3.3999e-01, -7.8844e-02, -1.0459e-01, -3.4586e-01,\n",
      "          2.8930e-01, -6.7773e-02,  5.0301e-02, -6.6727e-02, -2.7142e-01,\n",
      "         -1.3672e-01, -9.9663e-02,  2.6462e-01,  1.2556e-01,  1.3037e-01,\n",
      "          1.2082e-01, -6.0639e-02, -1.0667e-01,  1.1735e-01,  1.5790e-01,\n",
      "          2.6200e-02,  2.6616e-01, -2.4162e-01, -1.8631e-01,  1.8764e-01,\n",
      "         -3.1180e-01,  3.0791e-01, -5.4431e-01, -1.1983e-01, -1.0725e-01,\n",
      "         -1.8496e-01,  2.8428e-02, -5.4415e-02,  6.4604e-02,  6.5935e-03,\n",
      "          2.4668e-01,  1.7298e-01,  6.2383e-02, -2.4742e-02,  5.1912e-02,\n",
      "         -2.7216e-01, -1.7874e-01,  1.2582e-01, -4.3954e-02,  1.6627e-01,\n",
      "          2.1659e-01,  1.1313e-01,  1.5831e-01,  2.2108e-01,  2.2425e-01,\n",
      "          7.9096e-02, -2.1367e-01,  7.3454e-02,  1.2247e-01, -2.7916e-02,\n",
      "         -1.5296e-01, -1.5560e-01,  1.8266e-01, -1.7649e-03,  3.7558e-01,\n",
      "          1.8921e-01,  3.3974e-01,  1.1321e-01,  1.5872e-01, -7.4403e-02,\n",
      "          3.3558e-02, -1.6258e-01,  6.0345e-02, -1.0691e-01,  1.4355e-01,\n",
      "          2.4391e-01, -1.3940e-01, -1.0233e-01, -2.9786e-02,  1.1482e-01,\n",
      "          1.0395e-01, -4.0797e-02,  2.2105e-01,  3.0941e-01, -3.7951e-02,\n",
      "         -3.2004e-01,  2.0055e-02, -2.0374e-01,  8.2410e-02,  1.9801e-01,\n",
      "         -1.2336e-01,  2.0659e-01,  3.4422e-02,  3.8744e-02,  1.6061e-01,\n",
      "          4.3580e-02, -4.8605e-02, -1.7616e-01, -1.2680e-01, -6.1047e-03,\n",
      "         -1.7668e-02, -5.8111e-02, -1.3524e-01,  9.0141e-02, -7.7811e-03,\n",
      "         -2.5972e-02, -4.1177e-02, -1.9975e-01,  1.5209e-02, -8.6667e-02,\n",
      "          1.8835e-02, -3.7306e-02,  7.5527e-02, -1.8112e-01, -2.7433e-01,\n",
      "          2.0668e-01, -1.3264e-01, -2.2324e-01, -4.7018e-02,  8.7787e-02,\n",
      "         -2.0597e-01, -1.4815e-01,  1.0401e-01, -1.5663e-01,  2.9361e-02,\n",
      "         -2.0801e-01, -1.0770e-01,  2.0265e-01,  1.7936e-01, -1.1266e-01,\n",
      "          1.0336e-02,  2.5814e-01, -1.3523e-01],\n",
      "        [-1.6370e-01,  2.6367e-01, -2.9154e-02, -1.6190e-01, -2.5809e-01,\n",
      "          1.8359e-01, -6.9444e-02, -5.3576e-02, -1.9384e-01, -4.5957e-01,\n",
      "         -1.6423e-01, -7.5355e-02,  9.3222e-02,  3.2568e-01,  1.7958e-01,\n",
      "          5.2632e-02,  1.3048e-01, -2.9654e-02,  1.3289e-01,  3.5023e-02,\n",
      "          8.9066e-02,  8.9676e-03, -2.1801e-01, -2.8758e-01,  3.5896e-02,\n",
      "         -1.9760e-01,  2.8493e-01, -4.3945e-01,  1.2870e-02,  5.1823e-02,\n",
      "         -9.2144e-02,  9.4738e-02,  5.8257e-02,  2.2936e-01, -6.0064e-03,\n",
      "          3.1565e-01,  3.2812e-01, -8.6386e-02,  9.5911e-02,  1.3361e-01,\n",
      "         -2.6013e-01, -3.9153e-02,  2.6613e-01, -6.9672e-02,  1.1964e-01,\n",
      "          2.9889e-01,  1.1580e-01, -6.3541e-03,  2.3063e-01,  2.5777e-01,\n",
      "          9.3812e-02, -2.5513e-01,  4.0744e-02, -3.5277e-03,  6.5609e-02,\n",
      "         -4.4882e-02, -1.7119e-01,  1.6775e-01,  1.3007e-01,  3.3064e-01,\n",
      "         -2.3645e-02,  2.9538e-01, -8.9398e-02,  2.0776e-01, -2.8959e-02,\n",
      "         -9.9993e-02, -2.4486e-01,  9.3679e-02, -5.8208e-02,  8.7297e-02,\n",
      "          3.4600e-01, -1.3497e-02, -2.2390e-01, -7.9838e-02, -1.2622e-01,\n",
      "          1.0544e-01, -3.6690e-03,  7.1097e-02,  1.1758e-01, -1.9855e-02,\n",
      "         -1.5898e-01,  3.9397e-02, -6.2706e-02,  2.2147e-01,  4.4377e-02,\n",
      "          1.4216e-02,  1.8123e-01,  1.5031e-02,  5.6300e-02,  7.9753e-02,\n",
      "          1.5147e-01,  1.1469e-01, -2.3089e-01, -2.9336e-02, -2.5684e-02,\n",
      "         -5.9071e-02,  5.2072e-02, -7.5489e-02,  4.5954e-03, -5.7127e-03,\n",
      "         -2.5154e-03,  5.8493e-02, -1.2127e-01, -3.9491e-02,  5.2169e-02,\n",
      "         -7.3502e-02,  8.3544e-02,  1.2068e-01, -3.3546e-01, -2.6146e-01,\n",
      "          1.3655e-01, -7.0220e-02, -2.8446e-01, -2.0009e-01,  7.7636e-02,\n",
      "         -1.2650e-01, -1.3169e-01,  1.8662e-01, -1.2153e-01,  1.7730e-01,\n",
      "         -1.9366e-01, -8.8271e-03,  1.5541e-01,  1.8826e-01, -9.3382e-02,\n",
      "          1.7586e-02,  2.5615e-01, -1.5210e-02],\n",
      "        [ 1.7506e-01,  3.2562e-01,  7.4702e-02,  6.8775e-02, -2.6258e-01,\n",
      "          2.8877e-01, -1.3955e-03, -1.2279e-01, -2.2864e-01, -5.5680e-01,\n",
      "         -2.6315e-01, -3.4170e-02, -1.4192e-02,  2.3982e-01,  2.3992e-01,\n",
      "         -9.4214e-02, -2.1546e-02,  5.6468e-02,  2.0517e-01,  1.4909e-02,\n",
      "          1.7377e-01,  2.5368e-01, -1.5750e-01, -2.3888e-01,  3.0646e-02,\n",
      "         -4.1320e-01,  2.4442e-01, -2.2725e-01, -2.0362e-01,  8.7643e-02,\n",
      "         -1.2131e-01,  6.9221e-04, -3.3580e-02, -3.3227e-02,  4.7301e-02,\n",
      "          8.9192e-02,  3.1917e-01,  9.4007e-02, -1.4368e-02,  2.3955e-01,\n",
      "         -1.8901e-01, -8.0594e-02, -6.1863e-02, -1.5937e-01,  1.0868e-01,\n",
      "          1.0659e-01, -1.6735e-02,  1.7149e-01,  1.8859e-01,  7.5365e-02,\n",
      "          1.1610e-01, -1.9728e-01,  1.6777e-01, -6.9730e-02,  5.4893e-03,\n",
      "         -1.7058e-01, -2.0337e-01,  1.1468e-01, -1.0236e-01,  2.0674e-01,\n",
      "          5.6986e-03,  9.8412e-02, -7.1652e-03, -2.4813e-05,  1.4654e-01,\n",
      "         -5.7256e-03, -1.3243e-01,  5.1465e-02, -3.1202e-01,  6.0557e-03,\n",
      "          2.4872e-01, -4.9765e-02, -2.3059e-01, -5.4087e-02,  7.9946e-03,\n",
      "          1.5014e-01, -1.6961e-01,  7.6733e-02,  9.9904e-02,  1.5516e-01,\n",
      "         -1.4939e-01,  9.5987e-02, -6.5734e-02,  3.0193e-01,  2.6553e-02,\n",
      "         -1.8954e-01,  2.0287e-01,  3.2915e-04,  1.4555e-01,  1.9968e-01,\n",
      "          2.0549e-01, -1.1074e-01, -2.1235e-01,  9.8282e-04, -1.3303e-01,\n",
      "         -2.5968e-02, -7.1076e-02, -7.0057e-02, -8.9410e-02,  9.9108e-02,\n",
      "         -9.9482e-02,  1.9114e-01, -3.6187e-02, -4.7615e-02, -1.4047e-01,\n",
      "          1.1291e-01,  1.3731e-01,  1.2674e-01, -2.7239e-01, -3.6742e-01,\n",
      "         -4.8857e-02, -7.7658e-02, -2.9041e-01, -2.0923e-01,  9.3923e-02,\n",
      "         -1.0564e-01, -1.1774e-01,  1.2185e-01, -2.2677e-01,  2.2318e-02,\n",
      "         -7.7423e-02, -1.5687e-01,  2.1768e-01, -2.9738e-03, -8.6835e-02,\n",
      "         -3.0928e-01,  1.6012e-01, -2.1312e-01]]) torch.Size([4, 128])\n"
     ]
    }
   ],
   "source": [
    "def text_basic_moe():\n",
    "    x = torch.rand(4, 512)\n",
    "    basic_moe = BasicMoE(512, 128, 4)\n",
    "    output = basic_moe(x)\n",
    "    print(output.data, output.shape)\n",
    "\n",
    "text_basic_moe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
